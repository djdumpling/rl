{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204a3697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jaxtyping\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import tqdm\n",
    "import tabulate\n",
    "from eindex import eindex\n",
    "from jaxtyping import Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dd12e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdjdumpling\u001b[0m (\u001b[33mdjdumpling-yale\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/alexwa/Documents/GitHub/rl/rlhf_transformer/wandb/run-20250729_172300-q9ycy48u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/q9ycy48u' target=\"_blank\">proud-donkey-1</a></strong> to <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer' target=\"_blank\">https://wandb.ai/djdumpling-yale/rl-rlhf_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/q9ycy48u' target=\"_blank\">https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/q9ycy48u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('djdumpling-yale/rlhf_transformers/full-history-gpt2_20250727-211010:v0', type='responses')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4134d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model_artifact = run.use_artifact('djdumpling-yale/rlhf_transformers/full-history-gpt2_20250727-211010:v0', type='responses')\n",
    "model_dir = model_artifact.download()\n",
    "\n",
    "# Load the model and move to device\n",
    "model_path = os.path.join(model_dir, \"final_model.pt\")\n",
    "model = t.load(model_path, map_location=device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Function to generate text with the model\n",
    "def generate_sentiment(prompt, n_samples=5, max_tokens=50, temperature=0.7):\n",
    "    \"\"\"Generate text samples from the model with a given prompt.\"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # Get base model to tokenize input\n",
    "    input_ids = model.base_model.to_tokens(prompt, prepend_bos=True).to(device)\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        with t.inference_mode():\n",
    "            output_ids = model.base_model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                top_k=10,\n",
    "                stop_at_eos=True\n",
    "            )\n",
    "            sample = model.base_model.to_string(output_ids)\n",
    "            samples.append(sample)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"This movie was really\",  # Original training prompt\n",
    "    \"I just watched this film and it was\",  # New prompt\n",
    "    \"The acting in this movie was\",  # Focus on specific aspect\n",
    "    \"After seeing this movie, I felt\"  # Emotional response\n",
    "]\n",
    "\n",
    "# Generate and display samples\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"-\" * 50)\n",
    "    samples = generate_sentiment(prompt, n_samples=3)\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"{i}. {sample}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentiment classifier we used for training\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\").half().to(device)\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    \"\"\"Get sentiment score for a piece of text (1 = positive, 0 = negative)\"\"\"\n",
    "    tokens = cls_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"].to(device)\n",
    "    with t.inference_mode():\n",
    "        logits = cls_model(tokens).logits\n",
    "        probs = logits.softmax(-1)\n",
    "        positive_score = probs[:, 1].item()  # Probability of positive sentiment\n",
    "    return positive_score\n",
    "\n",
    "# Test a specific prompt with sentiment analysis\n",
    "test_prompt = \"This movie was really\"\n",
    "print(f\"\\nDetailed analysis for prompt: '{test_prompt}'\\n\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "samples = generate_sentiment(test_prompt, n_samples=5, temperature=0.7)\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    score = get_sentiment_score(sample)\n",
    "    sentiment = \"positive\" if score > 0.5 else \"negative\"\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Text: {sample}\")\n",
    "    print(f\"Sentiment Score: {score:.3f} ({sentiment})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention patterns for a specific generation\n",
    "def visualize_attention(prompt, layer_idx=None):\n",
    "    \"\"\"Visualize attention patterns for a given prompt\"\"\"\n",
    "    input_ids = model.base_model.to_tokens(prompt, prepend_bos=True).to(device)\n",
    "    \n",
    "    # Get attention patterns\n",
    "    with t.inference_mode():\n",
    "        _, cache = model.base_model.run_with_cache(\n",
    "            input_ids,\n",
    "            return_type=\"logits\",\n",
    "            names_filter=lambda name: name.endswith(\"pattern\")\n",
    "        )\n",
    "    \n",
    "    # Get the tokens for visualization\n",
    "    tokens = model.base_model.to_str_tokens(prompt, prepend_bos=True)\n",
    "    \n",
    "    # If no specific layer is provided, show the last layer\n",
    "    if layer_idx is None:\n",
    "        layer_idx = model.base_model.cfg.n_layers - 1\n",
    "    \n",
    "    # Get attention patterns for the specified layer\n",
    "    pattern = cache[f\"blocks.{layer_idx}.attn.pattern\"][0]  # [n_heads, seq_len, seq_len]\n",
    "    n_heads = pattern.shape[0]\n",
    "    \n",
    "    # Create a figure with subplots for each attention head\n",
    "    fig, axes = plt.subplots(2, n_heads//2, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for head_idx in range(n_heads):\n",
    "        ax = axes[head_idx]\n",
    "        attention = pattern[head_idx].cpu()\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(attention, ax=ax, cmap='viridis')\n",
    "        ax.set_title(f'Head {head_idx}')\n",
    "        ax.set_xticks(range(len(tokens)))\n",
    "        ax.set_yticks(range(len(tokens)))\n",
    "        ax.set_xticklabels(tokens, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(tokens, rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize attention patterns for our test prompt\n",
    "test_prompt = \"This movie was really good\"\n",
    "print(f\"Visualizing attention patterns for: '{test_prompt}'\")\n",
    "visualize_attention(test_prompt, layer_idx=11)  # Visualize the last layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f6477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
