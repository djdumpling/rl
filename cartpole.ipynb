{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import wandb\n",
    "import warnings\n",
    "\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "from jaxtyping import Bool, Float, Int\n",
    "from torch import nn, Tensor\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = t.device(\"mps\") if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else t.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(2)\n",
      "Observation space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "\n",
    "print(f\"Action space: {env.action_space}\") # Discrete(2), left or right action\n",
    "print(f\"Observation space: {env.observation_space}\") # Box(4), position, velocity, angle, angular velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the QNetwork with a simple 3-layer NN with 10k parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 10934\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_obs, num_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_obs, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_actions),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "net = QNetwork(num_obs = 4, num_actions = 2)\n",
    "num_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Parameters: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the replay buffer. Thought the add function was neat since it slices off old elements. \n",
    "Since using mps, need to tensorify the 5 returned arrays.\n",
    "\n",
    "I'm curious much the capacity affects the rate of catastrophic forgetting. Maybe exponential decay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    rng: np.random.Generator\n",
    "\n",
    "    def __init__(self, num_envs, obs_shape, action_shape, capacity, seed):\n",
    "        self.num_envs = num_envs\n",
    "        self.obs_shape = obs_shape\n",
    "        self.action_shape = action_shape\n",
    "        self.capacity = capacity\n",
    "        self.seed = seed\n",
    "\n",
    "        # obs, actions, rewards, next_obs, terminated\n",
    "        self.obs = np.empty((0, *self.obs_shape), dtype = np.float32)\n",
    "        self.actions = np.empty((0, *self.action_shape), dtype = np.float32)\n",
    "        self.rewards = np.empty(0, dtype = np.float32)\n",
    "        self.next_obs = np.empty((0, *self.obs_shape), dtype = np.float32)\n",
    "        self.terminated = np.empty(0, dtype = bool)\n",
    "\n",
    "    def add(self, obs, actions, rewards, next_obs, terminated):\n",
    "        self.obs = np.concatenate((self.obs, obs))[-self.capacity:]\n",
    "        self.actions = np.concatenate((self.actions, actions))[-self.capacity:]\n",
    "        self.rewards = np.concatenate((self.rewards, rewards))[-self.capacity:]\n",
    "        self.next_obs = np.concatenate((self.next_obs, next_obs))[-self.capacity:]\n",
    "        self.terminated = np.concatenate((self.terminated, terminated))[-self.capacity:]\n",
    "\n",
    "    def sample(self, batch_size, device):\n",
    "        indices = self.rng.integers(0, self.capacity, size = batch_size)\n",
    "\n",
    "        obs_tensor = t.tensor(self.obs[indices], dtype = t.float32, device = device)\n",
    "        actions_tensor = t.tensor(self.actions[indices], dtype = t.float32, device = device)\n",
    "        rewards_tensor = t.tensor(self.rewards[indices], dtype = t.float32, device = device)\n",
    "        next_obs_tensor = t.tensor(self.next_obs[indices], dtype = t.float32, device = device)\n",
    "        terminated_tensor = t.tensor(self.terminated[indices], dtype = t.bool, device = device)\n",
    "\n",
    "        return obs_tensor, actions_tensor, rewards_tensor, next_obs_tensor, terminated_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
