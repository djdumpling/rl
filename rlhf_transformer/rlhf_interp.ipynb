{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204a3697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jaxtyping\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torchrl\n",
    "import wandb\n",
    "import tqdm\n",
    "import tabulate\n",
    "\n",
    "from eindex import eindex\n",
    "from jaxtyping import Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torchrl.envs.llm import ChatEnv\n",
    "from torchrl.modules.llm import TransformersWrapper\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"mps\" if t.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d27e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdjdumpling\u001b[0m (\u001b[33mdjdumpling-yale\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/alexwa/Documents/GitHub/rl/rlhf_transformer/wandb/run-20250730_223647-ed1hg53q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/ed1hg53q' target=\"_blank\">drawn-sky-10</a></strong> to <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer' target=\"_blank\">https://wandb.ai/djdumpling-yale/rl-rlhf_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/ed1hg53q' target=\"_blank\">https://wandb.ai/djdumpling-yale/rl-rlhf_transformer/runs/ed1hg53q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-gpt2_20250730-004324:v0, 643.08MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:6.9 (93.6MB/s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: /Users/alexwa/Documents/GitHub/rl/rlhf_transformer/artifacts/model-gpt2_20250730-004324:v0\n",
      "Loading model from: /Users/alexwa/Documents/GitHub/rl/rlhf_transformer/artifacts/model-gpt2_20250730-004324:v0/final_model.pt\n",
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Successfully loaded model with TorchRL wrapper!\n"
     ]
    }
   ],
   "source": [
    "# load artifact from wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('djdumpling-yale/rlhf_transformers/model-gpt2_20250730-004324:v0', type='model')\n",
    "model_dir = artifact.download()\n",
    "\n",
    "# set location locally \n",
    "model_path = os.path.join(model_dir, \"final_model.pt\")\n",
    "state_dict = t.load(model_path, map_location=device)\n",
    "\n",
    "# get weights from RLHFed model\n",
    "base_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('base_model.'):\n",
    "        new_key = k.replace('base_model.', '')\n",
    "        base_state_dict[new_key] = v\n",
    "\n",
    "# load into gpt architecture\n",
    "base_model = HookedTransformer.from_pretrained(\"gpt2\", device=device)\n",
    "base_model.load_state_dict(base_state_dict)\n",
    "base_model.eval()\n",
    "\n",
    "# if TRL comes in later?\n",
    "model = TransformersWrapper(model=base_model, tokenizer=base_model.tokenizer,input_mode=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3cb996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0453307b2dcf4e82a32a85ca2def30f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'This movie was really great. The music was great, the characters were'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"disabled\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "base_model.generate(\"This movie was really\", max_new_tokens=10, temperature=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
